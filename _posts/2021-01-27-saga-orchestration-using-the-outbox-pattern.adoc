---
layout: post
title:  Saga Orchestration Using the Outbox Pattern
date:   2021-01-27
tags: [ discussion, patterns, outbox ]
author: gmorling
---

When moving to microservices, one of the first things to realize is that individual services don't exist in isolation.
While the aim is to create loosely coupled, independent services with as less interaction as possible,
chances are high that one service needs a particular data set owned by another service,
or that multiple services need to act in concert in order to achieve a consistent outcome of an operation in the domain of our business.

The link:/blog/2019/02/19/reliable-microservices-data-exchange-with-the-outbox-pattern/[outbox pattern, implemented via change data capture], is a proven approach for addressing the concern of data exchange between microservices;
Avoiding any unsafe "dual writes" to multiple resources, e.g. a database and a messaging broker,
the outbox pattern achieves eventual consistent data exchange,
without depending on the synchronous availability of all participants,
and not requiring distributed transaction protocols such as 2PC either.

In this post I'd like to explore how to take the outbox pattern to the next level and use it for implementing _sagas_,
potentially long-running business transactions which span across multiple microservices.
One common example is that of booking a travel comprising of multiple parts: either all flight legs and accommodation should be booked together, or none of them.
Sagas split up one such overarching business transaction into a series of multiple local database transactions.

+++<!-- more -->+++

For "rolling back" the overarching business transaction in case of a failure,
sagas rely on the notion of _compensating transactions_:
each previously applied local transaction must be able to be "undone" by running another transaction which applies the inversion of the formerly done changes.
Sagas are by no means a new concept, they have first been discussed by Hector Garcia-Molina and Kenneth  Salem in their SIGMOD '87 https://www.cs.cornell.edu/andru/cs711/2002fa/reading/sagas.pdf[Sagas] paper.
But as distributed transactions typically are not an option in microservices architectures,
sagas backed by local transactions within the participating services are seeing growing popularity these days.

To make things tangible, let's consider the example of an e-commerce business with three services, _order_, _customer_, and _payment_.
When a new purchase order is submitted to the _order_ service,
the following flow should be executed, also including the other two services,
which best is perceived as a state machine:

[.centered-image.responsive-image]
====
++++
<img src="/assets/images/saga/order-states.png" style="max-width:90%;" class="responsive-image" alt="Order state transitions">
++++
*Figure 1. Order state transitions*
====

First, we need to check with the _customer_ service whether the incoming order fits into the customer's credit limit
(as we don't want to have pending orders of one customer to pass a certain threshold).
So if for instance the customer has a credit limit of $500, and a new order with a value of $300 comes in,
the remaining limit will be $200.
A subsequent order with a value of $250 would be rejected accordingly,
as it would pass the customer's current open credit limit.

If the credit limit check succeeds,
the payment for the order needs to be requested via the _payment_ service.

If the credit approval fails,
the order will go to `Rejected` state right away.
If that steps succeeds but then the subsequent payment request fails,
the previously allocated credit limit needs to be released again,
before transitioning to the `rejected` state.
If credit approval and payment request succeed, the order transitions into `Accepted` state,
so fulfillment for it could begin (which is not part of the process discussed here).

== Implementation Choices

There are two general ways for implementing distributed sagas, _choreography_ and _orchestration_.
In the choreography approach, one participating service sends a message to the next after it has executed its local transaction.
With orchestration on the other hand, there's one coordinating service, which invokes one participant after the other
(either synchronously, e.g. via HTTP or gRPC, or (preferably) asynchronously, e.g. via message brokers or distributed logs such as Apache Kafka).

Both approaches have their pros and cons, e.g. see https://chrisrichardson.net/post/sagas/2019/08/04/developing-sagas-part-2.html[this post] by Chris Richardson for a more detailed discussion.
Personally, I'm preferring the orchestration approach, as it defines one central place which can be queried to obtain the current status of a particular saga (the orchestrator, or "saga execution coordinator", SEC for short).
Also it allows to add additional intermediary steps between two participants of the flow,
without the need to adjust them.

Before diving into the implementation of this interaction flow,
it's worth spending some time to think about the transactional semantics it provides.
So let's examine the four classic ACID properties of transactions:

* _**A** tomicity_: ✅ -- The pattern ensures that either all services apply the local transactions,
or, in case of a failure, all already executed local transactions are compensated
* _**C** onsistency_: ✅ -- All local constraints are guaranteed to be satisfied after successful execution of all the transactions making up the saga
* _**I** solation_: ❌ -- As local transactions are committed as the saga is running, their changes are already visible to other concurrent transactions, despite the possibility that the saga will fail eventually,
causing all transactions to be compensated. I.e. the isolation level is comparable to "read uncommitted"
* _**D** urability_: ✅ -- Once the local transactions of the saga have been committed, their changes are persisted and durable e.g. after a service failure and restart

From the perspective of the service consumer -- e.g. a user placing a purchase order with the _order_ service -- the system behaves eventually consistent;
i.e. after the `placeOrder()` call returns, it will take some time until the purchase order is in its correct state,
as per the logic of the different participating services.

== Recap: The Outbox Pattern

Now, how do the outbox pattern and change data capture (via Debezium, of course) fit into all this?
As said above, a saga coordinator should preferably communicate asynchronously with participating services,
via request and reply message channels.
Apache Kafka is a super-popular choice for implementing these channels.
But the orchestrator (and each participating service) also need to apply transactions to their specific databases in order to execute their parts of the overall saga flow.

While it might be tempting to simply execute a database transaction and send a corresponding message to Kafka shortly thereafter, this is not a good idea.
These two actions would not happen within a single transaction spanning the database and Kafka,
so it's only matter of time until we end up with an inconsistent state, when e.g. the database transaction commits but the write to Kafka fails.
But friends don't let friends do dual writes, and the outbox pattern is a very elegant way for addressing this issue:

[.centered-image.responsive-image]
====
++++
<img src="/assets/images/saga/outbox-pattern.png" style="max-width:90%;" class="responsive-image" alt="Safely updating the database and sending a message to Kafka via the outbox pattern">
++++
*Figure 2. Safely updating the database and sending a message to Kafka via the outbox pattern*
====

Instead of directly sending a message to Kafka when updating the database,
the service inserts the message into a specific _outbox table_ within its database.
This happens within a shared transaction, so either the changes to the service's model are persisted _and_ the message gets safely stored in the outbox table,
or _none_ of these changes gets applied.
Once the transaction has been written to the database's transaction log,
the Debezium change data capture process can pick up the outbox message from there and be sent to Apache Kafka.

This is done using _at-least-once_ semantics, i.e. it might happen the same outbox message is sent to Kafka multiple times.
This would happen in case of failures such as a crash of Debezium,
where it didn't get to persist its offset, i.e. the last log position it has read.
After a restart, it would then continue to read the transaction log from the last persisted offset position,
resulting in messages after that offset potentially being sent a second time.
In order to allow consumers to detect and ignore duplicated messages,
each message should have a unique id,
which e.g. in case of Debezium's Quarkus extension for sending outbox messages is a UUID that gets propagated as a Kafka message header.

== Implementing Sagas Using the Outbox Pattern

With the outbox pattern in our toolbox, things become a bit clearer;
the _order_ service, acting as the saga coordinator, triggers the entire flow after an incoming `placeOrder()` call, typically via a REST API,
by updating its own local state - comprising of the persisted order model and the saga execution log - and emitting a message to the first participating service, _customer_.
The other two saga participants react to messages which they receive via Kafka,
perform a local transaction which updates their own data state and emit a reply message for coordinator via their own outbox table.

The overall design looks like this:

[.centered-image.responsive-image]
====
++++
<img src="/assets/images/saga/saga-with-outbox.png" style="max-width:90%;" class="responsive-image" alt="Saga orchestration using the outbox pattern">
++++
*Figure 3. Saga orchestration using the outbox pattern*
====

You can find an example implementation of this architecture in the Debezium examples repository on GitHub.
The key parts of the architecture are these:

* The three services, _order_ (for managing purchase orders and acting as the saga orchestrator), _customer_ (for managing the customer's credit limit), and _payment_ (for handling credit card payments), each with their own local database (Postgres);
they are implemented using the https://quarkus.io/[Quarkus] stack
* Apache Kafka as the messaging backbone
* Debezium, running on top of Kafka Connect, subscribing to changes in the three different databases, and sending them to corresponding Kafka topics, using Debezium's outbox event routing SMT

Compared to synchronous communication e.g. via HTTP, implementing the Saga flow via the outbox pattern, CDC and Kafka allows the participants to be nicely decoupled.
If for instance the _customer_ service isn't up an running when the _order_ service receives a new purchase order,
this doesn't matter at all.
The same goes for Kafka or Debezium, the only resource required synchronously by the _order_ service is its own database.
Once components come back up again, they will pick up from the last committed offset and continue the data flow.

Inspired by architecture documentation templates such as arc42, let's switch perspectives and take a look at the _runtime view_ of the solution,
in order to better understand how messages flow between the different saga participants in case of a successful saga execution
(and yes, I go carried away a bit in drawing diagrams using Excalidraw while writing this post ;):

[.centered-image.responsive-image]
====
++++
<img src="/assets/images/saga/saga-sequence.png" style="max-width:90%;" class="responsive-image" alt="Execution sequence of a successful saga flow">
++++
*Figure 4. Execution sequence of a successful saga flow*
====

If for instance the payment step would fail (the customer's credit card has expired),...


Having discussed the message flow _between_ services, let's now dive into some implementation details, starting with the _order_ service.
The example implementation provides a generic saga orchestrator in form of a simple state machine and the order-specific saga implementation,
which will be discussed in more depth further below.
The "framework" part of the _order_ service's implementation keeps track of the current state of the saga execution within the `sagastate` table,
whose schema looks like this:

[source]
----
Column      |     Type     | Modifiers
------------+--------------+------------
id          | uuid         | not null
currentStep | varchar(255) |
payload     | varchar(255) |
status      | varchar(255) |
stepState   | varchar(255) |
type        | varchar(255) |
version     | int4         | not null
----

Its columns are these:

* `id`: Unique identifier of a given saga instance, representing the creation of one particular purchase order
* `currentStep`: The step at which the saga currently is, e.g. "credit-approval" or "payment"
* `payload`: An arbitrary data structure associated with a particular saga instance, e.g. containing the id or corresponding purchase order and other information useful during the saga lifecycle
* `status`: The current status of the saga; one of `STARTED`, `SUCCEEDED`, `ABORTING`, or `ABORTED`
* `stepState`: A string-ified JSON structure describing the status of the individual steps, e.g. `"{\"credit-approval\":\"SUCCEEDED\",\"payment\":\"STARTED\"}"`
* `type`: A nominal type of a saga, e.g. "order-placement"; useful to tell apart different kinds of sagas supported by one system
* `version`: An optimistic locking version, used to detect and reject concurrent updates to one saga instance (in which case the message triggering the failing update needs to be retried, re-loading the current state from the saga log)

As the _order_ services sends requests to the _customer_ and _payment_ services and receives their replies from Kafka,
the saga state gets updated within this table.
By setting up a Debezium connector for tracking the `sagastate` table, we can nicely examine the progress of a saga's execution in Kafka.

Here's the state transitions for a purchase order whose payment fails;
First, the order comes in and the "credit-approval" step gets started:

[source,json]
----
{
  "id": "17b572a2-cdc0-4501-8ec3-9eb2956b2b10",
  "currentstep": null,
  "payload": "{\"order-id\":2,\"customer-id\":456,\"payment-due\":4999,\"credit-card-no\":\"xxxx-yyyy-dddd-9999\"}",
  "status": "STARTED",
  "stepstate": "{}",
  "type": "order-placement",
  "version": 0
}
----

[source,json]
----
{
  "id": "17b572a2-cdc0-4501-8ec3-9eb2956b2b10",
  "currentstep": "credit-approval",
  "payload": "{\"order-id\":2,\"customer-id\":456, ...}",
  "status": "STARTED",
  "stepstate": "{\"credit-approval\":\"STARTED\"}",
  "type": "order-placement",
  "version": 1
}
----

At this point, a "credit-approval" request message has been persisted in the outbox table, too.
Once this has been sent to Kafka, the _customer_ service will process it and send a reply message.
The _order_ services processes this by updating the saga state an starting the payment step:

[source,json]
----
{
  "id": "17b572a2-cdc0-4501-8ec3-9eb2956b2b10",
  "currentstep": "payment",
  "payload": "{\"order-id\":2,\"customer-id\":456, ...}",
  "status": "STARTED",
  "stepstate": "{\"credit-approval\":\"SUCCEEDED\",\"payment\":\"STARTED\"}",
  "type": "order-placement",
  "version": 2
}
----

Again a message is sent via the outbox table, now the "payment" request.
This fails, and the _payment_ system responds with a reply message indicating this fact.
So the payment gets aborted:

[source,json]
----
{
  "id": "17b572a2-cdc0-4501-8ec3-9eb2956b2b10",
  "currentstep": "payment",
  "payload": "{\"order-id\":2,\"customer-id\":456, ...}",
  "status": "ABORTING",
  "stepstate": "{\"credit-approval\":\"SUCCEEDED\",\"payment\":\"ABORTING\"}",
  "type": "order-placement",
  "version": 3
}
----

Once that has been confirmed by the _payment_ system, the "credit-approval" step needs to be compensated, too:

[source,json]
----
{
  "id": "17b572a2-cdc0-4501-8ec3-9eb2956b2b10",
  "currentstep": "credit-approval",
  "payload": "{\"order-id\":2,\"customer-id\":456, ...}",
  "status": "ABORTING",
  "stepstate": "{\"credit-approval\":\"ABORTING\",\"payment\":\"ABORTED\"}",
  "type": "order-placement",
  "version": 4
}
----

Finally, both steps as well as the entire saga instance are in the `ABORTED` state:

[source,json]
----
{
  "id": "17b572a2-cdc0-4501-8ec3-9eb2956b2b10",
  "currentstep": "credit-approval",
  "payload": "{\"order-id\":2,\"customer-id\":456, ...}",
  "status": "ABORTED",
  "stepstate": "{\"credit-approval\":\"ABORTED\",\"payment\":\"ABORTED\"}",
  "type": "order-placement",
  "version": 5
}
----

You can try out things yourself by following instructions in the example's README file,
where you'll find requests for placing successful as well as failing order creations.
It also has instructions for examining the exchanged messages in the Kafka topics sourced from the outbox tables of the different services.

The saga flow gets started within the _order_ service's REST endpoint implementation like so:

[source,java]
----
@POST
@Transactional
public PlaceOrderResponse placeOrder(PlaceOrderRequest req) {
    PurchaseOrder order = req.toPurchaseOrder();
    order.persist(); // <1>

    sagaManager.begin(OrderPlacementSaga.class, OrderPlacementSaga.payloadFor(order)); // <2>

    return PlaceOrderResponse.fromPurchaseOrder(order);
}
----
<1> Persist the incoming purchase order
<2> Begin the order placement saga flow for the incoming order

`SagaManager#begin()` will create a new record in the `sagastate` table, obtain the first outbox event from the `OrderPlacementSaga` implementation and persist it in the outbox table.

`OrderPlacementSaga` implements all the use case specific parts of the saga flow:

* outbox events to be sent for executing one part of the saga flow
* outbox events for compensating one part of the saga flow
* event handlers for processing reply messages from the othe saga participants

The `OrderPlacementSaga` implementation is a tad too long for showing it here in its entirety
(you can find its complete source here on GitHub),
but here are some key parts:

[source,java]
----
@Saga(type="order-placement", stepIds = {CREDIT_APPROVAL, PAYMENT}) // <1>
public class OrderPlacementSaga extends SagaBase {

  private static final String REQUEST = "REQUEST";
  private static final String CANCEL = "CANCEL";
  protected static final String PAYMENT = "payment";
  protected static final String CREDIT_APPROVAL = "credit-approval";

  // ...

  @Override
  public SagaStepMessage getStepMessage(String id) { // <2>
    if (id.equals(PAYMENT)) {
      return new SagaStepMessage(PAYMENT, REQUEST, getPayload());
    }
    else {
      return new SagaStepMessage(CREDIT_APPROVAL, REQUEST, getPayload());
    }
  }

  @Override
  public SagaStepMessage getCompensatingStepMessage(String id) { // <3>
    // ...
  }

  public void onPaymentEvent(PaymentEvent event) { // <4>
    if (alreadyProcessed(event.messageId)) {
      return;
    }

    onStepEvent(PAYMENT, event.status.toStepStatus());
    updateOrderStatus();

    processed(event.messageId);
  }

  public void onCreditApprovalEvent(CreditApprovalEvent event) { // <5>
     // ...
  }

  private void updateOrderStatus() { // <6>
    if (getStatus() == SagaStatus.COMPLETED) {
      PurchaseOrder order = PurchaseOrder.findById(getOrderId());
      order.status = PurchaseOrderStatus.ACCEPTED;
    }
    else if (getStatus() == SagaStatus.ABORTED) {
      PurchaseOrder order = PurchaseOrder.findById(getOrderId());
      order.status = PurchaseOrderStatus.CANCELLED;
    }
  }

  // ...
}
----
<1> The ids of the saga steps in order of execution
<2> Returns the outbox message to be emitted for the given step
<3> Returns the outbox message to be emitted for compensating the given step
<4> Event handler for "payment" reply messages; it will update the purchase order status as well as the saga status (via the `onStepEvent()` callback),
which depending on the status may either complete the saga or initiate its rollback by applying all the compensating messages
<5> Event handler for "credit approval" reply messages
<6> Updates the purchase order status, based on the current saga states

To simplify interactions with the respective outbox tables, the three services use Debezium's link:/documentation/reference/integrations/outbox.html[Quarkus extension] for persisting outbox messages.
This extension allows to emit outbox events by firing CDI events,
whose payload is persisted in the outbox table as part of the ongoing local database transaction:

[source,java]
----
...
this.outboxEvent.fire(CreditEvent.of(sagaId, CreditStatus.CANCELLED));
...
----

Each service also has a journal table with the ids of consumed messages,
allowing to identify and exclude duplicated messages after an un-clean connector shutdown.

The implementation of the _customer_ and _payment_ services isn't anything fundamentally now,
so they are omitted here for the sake of brevity.
You can find their complete source code here.

== When Things Go Wrong

A key part of implementing distributed interaction patterns like sagas is understanding how they behave in failure scenarios and making sure that (eventual) consistency is also achieved under such unforeseen circumstances.

Note that a negative outcome by any of the saga participants (e.g. if the _payment_ service rejects the payment due to an invalid credit card) is not a failure scenario here;
it is explicitly expected that participants cannot successfully execute their part of the overall flow,
resulting in the execution of appropriate compensating local transactions.
This also means that such generally anticipated failure of execution must not result in a rollback of the local database transaction,
as otherwise no reply message would be sent back to the orchestrator via the outbox.

With that in mind, let's discuss some actual failure scenarios:

The event handler of a Kafka message raises an exception:: the local database transaction will be rolled back and the incoming Kafka message will not be acknowledged with the broker; depending on the kind of exception, it may be retried after some time. In any case, monitoring should be in place to detect this situation, as the saga flow won't be able to continue until the message has been processed
The Debezium connector crashes after sending an outbox message to Kafka, but before committing the offset in the source database's transaction log:: After restarting the connector, it will continue to read the messages from the outbox table beginning at the log offset that was committed last, potentially resulting in some outbox events sent a second time; that's why all the participants need to be idempotent, as implemented in the example by means of journal tables which allow to detect if the same event is processed a second time
The Kafka broker isn't running or cannot be reached, e.g. due to a network split:: The Debezium connectors can resume their work once Kafka is available and accessable again; until then, saga flows naturally cannot proceed
A message gets processed, but acknowledging it with Kafka fails:: The message will be passed to the consuming service again, which would find the message's id in its journal table and thus ignore the duplicated message
Concurrent updates to the saga state table when processing multiple saga steps in parallel:: While we've discussed a sequential flow with the orchestrator triggering participating services one after another, one might also envision a saga implementation which processes multiple steps in parallel. In this case,
concurrently arriving reply messages may compete to update the saga state table. This situation would be detected via the optimistic locking implemented on that table, causing an event handler trying to commit an update based on a superseded version of the saga state to fail, rollback and retry

We could discuss some more cases, but the general semantics of the overall design are those of an eventually consistent system with at-least-once guarantees.

== Bonus: Distributed Tracing

When designing an event flow between distributed systems, operational insight is a key aspect of making sure everything runs correctly and efficiently.
Distributed tracing helps with that by collecting trace information from the individual systems that contribute to such interaction and allowing to examine the call flows e.g. in a web UI.

Debezium's outbox support addresses this concern through tight integration with the OpenTracing spec (support for OpenTelemetry is on the roadmap).
By putting a tool such Jaeger into place, it's just a matter of configuration to collect trace information from the _order_, _customer_, and _payment_ services and display the end-to-end spans.

[.centered-image.responsive-image]
====
++++
<img src="/assets/images/saga/open-tracing.png" style="max-width:90%;" class="responsive-image" alt="Saga flow in the Jaeger UI">
++++
*Figure 5. Saga flow in the Jaeger UI*
====

The visualization flow in Jaeger nicely shows, how the saga flow is triggered by the incoming REST request in the _order_ service,
an outbox message is sent to _customer_ and back to _order_,
followed by another one sent to _payment_ and back to _order_.
The tracing functionality makes it rather easy to identify unfinished flows
-- e.g. because an event handler in one of the participating services fails to process a message --
as well as performance bottlenecks,
e.g. one event handler taking particularly long for fulfilling its part of the saga flow.

== Wrap-Up

The saga pattern is a very interesting option for implementing long-running "business transactions" which require multiple, separate services to agree on either applying or aborting a set of data changes.
Where distributed transaction protocols like XA would have been a popular implementation choice in the past,
they typically are not an option in microservices architectures.
Services may use non-XA compatible data stores internally, Apache Kafka as a popular infrastructure for message exchange between microservices also doesn't support integration with XA transaction managers.

Of course we should aspire for a service cut which doesn't require interaction with remote services in the first place.
But depending on business requirements, the need for such interaction spanning multiple services may be impossible to avoid,
in particular when it comes to integrating legacy systems or systems which are not under our control.




On a related note it's critical to be aware of the implications of the limited isolation level of the overarching business transaction.
For instance the allocation of parts of the customer's credit limit may cause another, concurrently submitted order by that customer, to be rejected, also if this first order eventually also would be rejected, e.g. due to a failure with its payment.
bBut

Kogito
microprofile lra
optimistic locking
parallelization
how to deal with writes on pending objects
systems must offer compensation facility
ordering of outbox events
dangling messages

== Probably To be Left Out

As an example, here is the event handler of the _customer_ service for processing the "credit approval" events:

[source,java]
----
@ApplicationScoped
@Traced
public class CreditEventHandler {

    private static final Logger LOGGER = LoggerFactory.getLogger(CreditEventHandler.class);

    @Inject
    MessageLog log;

    @Inject
    Event<ExportedEvent<?, ?>> outboxEvent;

    @Transactional
    public void onCreditEvent(UUID eventId, UUID sagaId, CreditLimitEvent event) {
        if (log.alreadyProcessed(eventId)) { // <1>
            LOGGER.info("Event with UUID {} was already retrieved, ignoring it", eventId);
            return;
        }

        Customer customer = Customer.findById(event.customerId);

        CreditStatus status;

        if (event.type == CreditRequestType.REQUEST) {
            if (customer.fitsCreditLimit(event.paymentDue)) { // <2>
                status = CreditStatus.APPROVED;
                customer.allocateCreditLimit(event.paymentDue);
            }
            else {
                status = CreditStatus.REJECTED; // <3>
            }
        }
        else {
            customer.releaseCreditLimit(event.paymentDue); // <4>
            status = CreditStatus.CANCELLED;
        }

        this.outboxEvent.fire(CreditEvent.of(sagaId, status)); // <5>

        log.processed(eventId); // <6>
    }
 }
----
<1> Check whether the incoming message has been processed before; if so, abort
<2> The incoming event represents a request to allocate the given order value within the customer's credit limit,
which still is large enough to accomodate for that new purchase order
<3> The purchase order of the incoming event would exceed the customer's credit limit, so the request needs to be rejected
<4> The incoming order represents a compensation request for a previous limit allocation, so deduct the order value from the customer's limit
<5> Emit an outbox event with the outcome of the transaction
<6> Mark the message as processed in the journal
