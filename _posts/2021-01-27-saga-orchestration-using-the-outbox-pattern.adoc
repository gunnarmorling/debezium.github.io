---
layout: post
title:  Saga Orchestration Using the Outbox Pattern
date:   2021-01-27
tags: [ discussion, patterns, outbox ]
author: gmorling
---

When moving to microservices, one of the first things to realize is that individual services don't exist in isolation.
While the aim is to create loosely coupled, independent services with as little interaction as possible,
chances are high that one service needs a particular data set owned by another service,
or that multiple services need to act in concert in order to achieve a consistent outcome of an operation in the domain of our business.

The link:/blog/2019/02/19/reliable-microservices-data-exchange-with-the-outbox-pattern/[outbox pattern, implemented via change data capture], is a proven approach for addressing the concern of data exchange between microservices;
Avoiding any unsafe "dual writes" to multiple resources, e.g. a database and a messaging broker,
the outbox pattern achieves eventual consistent data exchange,
without depending on the synchronous availability of all participants,
and not requiring distributed transaction protocols such as 2PC either.

In this post I'd like to explore how to take the outbox pattern to the next level and use it for implementing _sagas_,
potentially long-running business transactions which span across multiple microservices.
One common example is that of booking a travel comprising multiple parts: either all flight legs and accommodation should be booked together, or none of them.
Sagas split up one such overarching business transaction into a series of multiple local database transactions.

+++<!-- more -->+++

For "rolling back" the overarching business transaction in case of a failure,
sagas rely on the notion of _compensating transactions_:
each previously applied local transaction must be able to be "undone" by running another transaction which applies the inversion of the formerly done changes.
Sagas are by no means a new concept, they have first been discussed by Hector Garcia-Molina and Kenneth  Salem in their SIGMOD '87 https://www.cs.cornell.edu/andru/cs711/2002fa/reading/sagas.pdf[Sagas] paper.
But as distributed transactions typically are not an option in microservices architectures,
sagas backed by local transactions within the participating services are seeing growing popularity these days.

To make things tangible, let's consider the example of an e-commerce business with three services, _order_, _customer_, and _payment_.
When a new purchase order is submitted to the _order_ service,
the following flow should be executed, also including the other two services,
which best is perceived as a state machine:

[.centered-image.responsive-image]
====
++++
<img src="/assets/images/saga/order-states.png" style="max-width:90%;" class="responsive-image" alt="Order state transitions">
++++
*Figure 1. Order state transitions*
====

First, we need to check with the _customer_ service whether the incoming order fits into the customer's credit limit
(as we don't want to have pending orders of one customer to pass a certain threshold).
So if for instance the customer has a credit limit of $500, and a new order with a value of $300 comes in,
the remaining limit will be $200.
A subsequent order with a value of $250 would be rejected accordingly,
as it would pass the customer's current open credit limit.

If the credit limit check succeeds,
the payment for the order needs to be requested via the _payment_ service.

If the credit approval fails,
the order will go to the `Rejected` state right away.
If that step succeeds but then the subsequent payment request fails,
the previously allocated credit limit needs to be released again,
before transitioning to the `rejected` state.
If credit approval and payment request succeed, the order transitions into `Accepted` state,
so fulfillment for it could begin (which is not part of the process discussed here).

== Implementation Choices

There are two general ways for implementing distributed sagas, _choreography_ and _orchestration_.
In the choreography approach, one participating service sends a message to the next after it has executed its local transaction.
With orchestration on the other hand, there's one coordinating service, which invokes one participant after the other.

Both approaches have their pros and cons, e.g. see https://chrisrichardson.net/post/sagas/2019/08/04/developing-sagas-part-2.html[this post] by Chris Richardson and https://medium.com/@ydorego/microservices-orchestration-vs-choreography-the-eternal-saga-d58c35e07d81[this one] by Yves do Régo for a more detailed discussion.
Personally, I'm preferring the orchestration approach, as it defines one central place which can be queried to obtain the current status of a particular saga (the orchestrator, or "saga execution coordinator", SEC for short).
As it avoids point-to-point communication between participants (other than the orchestrator),
it also allows to add additional intermediary steps between two participants of the flow,
without the need to adjust them.

Before diving into the implementation of this interaction flow,
it's worth spending some time to think about the transactional semantics it provides.
So let's examine the four classic ACID properties of transactions:

* _**A** tomicity_: ✅ -- The pattern ensures that either all services apply the local transactions,
or, in case of a failure, all already executed local transactions are compensated
* _**C** onsistency_: ✅ -- All local constraints are guaranteed to be satisfied after successful execution of all the transactions making up the saga
* _**I** solation_: ❌ -- As local transactions are committed as the saga is running, their changes are already visible to other concurrent transactions, despite the possibility that the saga will fail eventually,
causing all transactions to be compensated. I.e. the isolation level is comparable to "read uncommitted"
* _**D** urability_: ✅ -- Once the local transactions of the saga have been committed, their changes are persisted and durable e.g. after a service failure and restart

From the perspective of the service consumer -- e.g. a user placing a purchase order with the _order_ service -- the system behaves eventually consistent;
i.e. after the `placeOrder()` call returns, it will take some time until the purchase order is in its correct state,
as per the logic of the different participating services.

As far as the communication between the participating services is concerned,
this may happen either synchronously, e.g. via HTTP or gRPC, or asynchronously, e.g. via message brokers or distributed logs such as Apache Kafka.
While the former often is a popular choice due to its perceived simplicity,
synchronous communication in distributed systems comes with quite a few disadvantages.
A step in the saga flow will only complete if the target service is available at this point in time.
While techniques like buffering or retrying requests may help, they are not without their own complexities.
An asynchronous implementation e.g. via Kafka avoids these issues,
as the availability of consuming services doesn't impact the sending service,
and as we'll see in the next section, not even availability of Kafka itself is a concern, thanks to change data capture.

== Recap: The Outbox Pattern

Now, how do the outbox pattern and change data capture (via Debezium, of course) fit into all this?
As said above, a saga coordinator should preferably communicate asynchronously with participating services,
via request and reply message channels.
Apache Kafka is a super-popular choice for implementing these channels.
But the orchestrator (and each participating service) also need to apply transactions to their specific databases in order to execute their parts of the overall saga flow.

While it might be tempting to simply execute a database transaction and send a corresponding message to Kafka shortly thereafter, this is not a good idea.
These two actions would not happen within a single transaction spanning the database and Kafka,
so it's only a matter of time until we end up with an inconsistent state, when e.g. the database transaction commits but the write to Kafka fails.
But friends don't let friends do dual writes, and the outbox pattern is a very elegant way for addressing this issue:

[.centered-image.responsive-image]
====
++++
<img src="/assets/images/saga/outbox-pattern.png" style="max-width:90%;" class="responsive-image" alt="Safely updating the database and sending a message to Kafka via the outbox pattern">
++++
*Figure 2. Safely updating the database and sending a message to Kafka via the outbox pattern*
====

Instead of directly sending a message to Kafka when updating the database,
the service inserts the message into a specific _outbox table_ within its database.
This happens within a shared transaction, so either the changes to the service's model are persisted _and_ the message gets safely stored in the outbox table,
or _none_ of these changes gets applied.
Once the transaction has been written to the database's transaction log,
the Debezium change data capture process can pick up the outbox message from there and be sent to Apache Kafka.

This is done using _at-least-once_ semantics, i.e. it might happen the same outbox message is sent to Kafka multiple times.
This would happen in case of failures such as a crash of Debezium,
where it didn't get to persist its offset, i.e. the last log position it has read.
After a restart, it would then continue to read the transaction log from the last persisted offset position,
resulting in messages after that offset potentially being sent a second time.
In order to allow consumers to detect and ignore duplicated messages,
each message should have a unique id,
which e.g. in case of Debezium's Quarkus extension for sending outbox messages is a UUID that gets propagated as a Kafka message header.

== Implementing Sagas Using the Outbox Pattern

With the outbox pattern in our toolbox, things become a bit clearer;
the _order_ service, acting as the saga coordinator, triggers the entire flow after an incoming `placeOrder()` call, typically via a REST API,
by updating its own local state - comprising of the persisted order model and the saga execution log - and emitting a message to the first participating service, _customer_.
The other two saga participants react to messages which they receive via Kafka,
perform a local transaction which updates their own data state and emit a reply message for coordinator via their own outbox table.

The overall design looks like this:

[.centered-image.responsive-image]
====
++++
<img src="/assets/images/saga/saga-with-outbox.png" style="max-width:90%;" class="responsive-image" alt="Saga orchestration using the outbox pattern">
++++
*Figure 3. Saga orchestration using the outbox pattern*
====

You can find an example implementation of this architecture in the Debezium examples repository on GitHub.
The key parts of the architecture are these:

* The three services, _order_ (for managing purchase orders and acting as the saga orchestrator), _customer_ (for managing the customer's credit limit), and _payment_ (for handling credit card payments), each with their own local database (Postgres)
* Apache Kafka as the messaging backbone
* Debezium, running on top of Kafka Connect, subscribing to changes in the three different databases, and sending them to corresponding Kafka topics, using Debezium's outbox event routing SMT

The three services are implemented using https://quarkus.io/[Quarkus], which is a stack for building cloud-native microservices running on the JVM as well as as native binaries (via GraalVM).
Of course, the pattern could also be implemented using other stacks or even languages.

There are for Kafka topics involved: a request and a response topic for the credit approval messages, and a request and a response topic for the payment messages.
In case of a successful saga execution, exactly four messages would be exchanged.
If one of the steps fail and a compensation is necessary,
there'd be additional request/response messages for each step to be compensated.

[NOTE]
.Ordering Guarantees
====
For scaling purposes, Kafka topics can be organized into multiple partitions.

Only within a partition it is guaranteed that a consumer will receive the messages in exactly the same order as they have been sent by the producer.
As by default all messages with the same key will go into one and the same partition,
the unique id of a saga is used as the message key.
That way, the correct order of processing of the messages pertaining to one saga instance is guaranteed.

Several saga instances can be processed in parallel if they end up in different partitions of the topics used for the saga message exchange.
====

Inspired by architecture documentation templates such as https://arc42.org/download[arc42],
let's switch perspectives and take a look at the _runtime view_ of the solution,
in order to better understand how messages flow between the different saga participants in case of a successful saga execution
(and yes, I go carried away a bit drawing diagrams using https://excalidraw.com/[Excalidraw] while writing this post ;):

[.centered-image.responsive-image]
====
++++
<img src="/assets/images/saga/saga-sequence.png" style="max-width:90%;" class="responsive-image" alt="Execution sequence of a successful saga flow">
++++
*Figure 4. Execution sequence of a successful saga flow*
====

Each service emits outgoing messages via its local outbox table.
From there, the messages are captured via Debezium and sent to Kafka, and finally consumed by the receiving service.

Now, what happens if one step of the flow is failing?
For instance let's assume the payment step fails, as the customer's credit card has expired.
In that case, the previously reserved credit amount in the _customer_ service needs to be released again.
To do so, the _order_ service sends a compensation request to the _customer_ service.
Zooming out a bit (as the details around Debezium and Kafka are the same as before),
this is how the message exchange would look like:

[.centered-image.responsive-image]
====
++++
<img src="/assets/images/saga/compensation-flow.png" style="max-width:90%;" class="responsive-image" alt="Execution sequence of a saga flow with compensation">
++++
*Figure 5. Execution sequence of a saga flow with compensation*
====

Having discussed the message flow _between_ services, let's now dive into some implementation details, starting with the _order_ service.
The example implementation provides a generic saga orchestrator in form of a simple state machine and the order-specific saga implementation,
which will be discussed in more depth further below.
The "framework" part of the _order_ service's implementation keeps track of the current state of the saga execution within the `sagastate` table,
whose schema looks like this:

[source]
----
Column      |     Type      | Modifiers
------------+---------------+------------
id          | uuid          | not null
currentStep | varchar(2000) |
payload     | varchar(2000) |
status      | varchar(2000) |
stepState   | varchar(2000) |
type        | varchar(2000) |
version     | int4          | not null
----

Its columns are these:

* `id`: Unique identifier of a given saga instance, representing the creation of one particular purchase order
* `currentStep`: The step at which the saga currently is, e.g. "credit-approval" or "payment"
* `payload`: An arbitrary data structure associated with a particular saga instance, e.g. containing the id or corresponding purchase order and other information useful during the saga lifecycle
* `status`: The current status of the saga; one of `STARTED`, `SUCCEEDED`, `ABORTING`, or `ABORTED`
* `stepState`: A string-ified JSON structure describing the status of the individual steps, e.g. `"{\"credit-approval\":\"SUCCEEDED\",\"payment\":\"STARTED\"}"`
* `type`: A nominal type of a saga, e.g. "order-placement"; useful to tell apart different kinds of sagas supported by one system
* `version`: An optimistic locking version, used to detect and reject concurrent updates to one saga instance (in which case the message triggering the failing update needs to be retried, re-loading the current state from the saga log)

As the _order_ service sends requests to the _customer_ and _payment_ services and receives their replies from Kafka,
the saga state gets updated within this table.
By setting up a Debezium connector for tracking the `sagastate` table, we can nicely examine the progress of a saga's execution in Kafka.

Here's the state transitions for a purchase order whose payment fails;
First, the order comes in and the "credit-approval" step gets started:

[source,json]
----
{
  "id": "17b572a2-cdc0-4501-8ec3-9eb2956b2b10",
  "currentstep": null,
  "payload": "{\"order-id\":2,\"customer-id\":456,\"payment-due\":4999,\"credit-card-no\":\"xxxx-yyyy-dddd-9999\"}",
  "status": "STARTED",
  "stepstate": "{}",
  "type": "order-placement",
  "version": 0
}
----

[source,json]
----
{
  "id": "17b572a2-cdc0-4501-8ec3-9eb2956b2b10",
  "currentstep": "credit-approval",
  "payload": "{\"order-id\":2,\"customer-id\":456, ...}",
  "status": "STARTED",
  "stepstate": "{\"credit-approval\":\"STARTED\"}",
  "type": "order-placement",
  "version": 1
}
----

At this point, a "credit-approval" request message has been persisted in the outbox table, too.
Once this has been sent to Kafka, the _customer_ service will process it and send a reply message.
The _order_ services processes this by updating the saga state and starting the payment step:

[source,json]
----
{
  "id": "17b572a2-cdc0-4501-8ec3-9eb2956b2b10",
  "currentstep": "payment",
  "payload": "{\"order-id\":2,\"customer-id\":456, ...}",
  "status": "STARTED",
  "stepstate": "{\"credit-approval\":\"SUCCEEDED\",\"payment\":\"STARTED\"}",
  "type": "order-placement",
  "version": 2
}
----

Again a message is sent via the outbox table, now the "payment" request.
This fails, and the _payment_ system responds with a reply message indicating this fact.
This means that the "credit-approval" step needs to be compensated via the _customer_ system:
[source,json]
----
{
  "id": "17b572a2-cdc0-4501-8ec3-9eb2956b2b10",
  "currentstep": "payment",
  "payload": "{\"order-id\":2,\"customer-id\":456, ...}",
  "status": "ABORTING",
  "stepstate": "{\"credit-approval\":\"ABORTING\",\"payment\":\"FAILED\"}",
  "type": "order-placement",
  "version": 3
}
----

Once that has succeeded, the saga is in its final state, `ABORTED`:

[source,json]
----
{
  "id": "17b572a2-cdc0-4501-8ec3-9eb2956b2b10",
  "currentstep": "credit-approval",
  "payload": "{\"order-id\":2,\"customer-id\":456, ...}",
  "status": "ABORTED",
  "stepstate": "{\"credit-approval\":\"ABORTED\",\"payment\":\"ABORTED\"}",
  "type": "order-placement",
  "version": 4
}
----

You can try out things yourself by following instructions in the example's README file,
where you'll find requests for placing successful as well as failing order creations.
It also has instructions for examining the exchanged messages in the Kafka topics sourced from the outbox tables of the different services.

The saga flow gets started within the _order_ service's REST endpoint implementation like so:

[source,java]
----
@POST
@Transactional
public PlaceOrderResponse placeOrder(PlaceOrderRequest req) {
    PurchaseOrder order = req.toPurchaseOrder();
    order.persist(); // <1>

    sagaManager.begin(OrderPlacementSaga.class, OrderPlacementSaga.payloadFor(order)); // <2>

    return PlaceOrderResponse.fromPurchaseOrder(order);
}
----
<1> Persist the incoming purchase order
<2> Begin the order placement saga flow for the incoming order

`SagaManager#begin()` will create a new record in the `sagastate` table, obtain the first outbox event from the `OrderPlacementSaga` implementation and persist it in the outbox table.

`OrderPlacementSaga` implements all the use case specific parts of the saga flow:

* outbox events to be sent for executing one part of the saga flow
* outbox events for compensating one part of the saga flow
* event handlers for processing reply messages from the othe saga participants

The `OrderPlacementSaga` implementation is a tad too long for showing it here in its entirety
(you can find its complete source here on GitHub),
but here are some key parts:

[source,java]
----
@Saga(type="order-placement", stepIds = {CREDIT_APPROVAL, PAYMENT}) // <1>
public class OrderPlacementSaga extends SagaBase {

  private static final String REQUEST = "REQUEST";
  private static final String CANCEL = "CANCEL";
  protected static final String PAYMENT = "payment";
  protected static final String CREDIT_APPROVAL = "credit-approval";

  // ...

  @Override
  public SagaStepMessage getStepMessage(String id) { // <2>
    if (id.equals(PAYMENT)) {
      return new SagaStepMessage(PAYMENT, REQUEST, getPayload());
    }
    else {
      return new SagaStepMessage(CREDIT_APPROVAL, REQUEST, getPayload());
    }
  }

  @Override
  public SagaStepMessage getCompensatingStepMessage(String id) { // <3>
    // ...
  }

  public void onPaymentEvent(PaymentEvent event) { // <4>
    if (alreadyProcessed(event.messageId)) {
      return;
    }

    onStepEvent(PAYMENT, event.status.toStepStatus());
    updateOrderStatus();

    processed(event.messageId);
  }

  public void onCreditApprovalEvent(CreditApprovalEvent event) { // <5>
     // ...
  }

  private void updateOrderStatus() { // <6>
    if (getStatus() == SagaStatus.COMPLETED) {
      PurchaseOrder order = PurchaseOrder.findById(getOrderId());
      order.status = PurchaseOrderStatus.ACCEPTED;
    }
    else if (getStatus() == SagaStatus.ABORTED) {
      PurchaseOrder order = PurchaseOrder.findById(getOrderId());
      order.status = PurchaseOrderStatus.CANCELLED;
    }
  }

  // ...
}
----
<1> The ids of the saga steps in order of execution
<2> Returns the outbox message to be emitted for the given step
<3> Returns the outbox message to be emitted for compensating the given step
<4> Event handler for "payment" reply messages; it will update the purchase order status as well as the saga status (via the `onStepEvent()` callback),
which depending on the status may either complete the saga or initiate its rollback by applying all the compensating messages
<5> Event handler for "credit approval" reply messages
<6> Updates the purchase order status, based on the current saga states

To simplify interactions with the respective outbox tables, the three services use Debezium's link:/documentation/reference/integrations/outbox.html[Quarkus extension] for persisting outbox messages.
This extension allows to emit outbox events by firing CDI events,
whose payload is persisted in the outbox table as part of the ongoing local database transaction:

[source,java]
----
...
this.outboxEvent.fire(CreditEvent.of(sagaId, CreditStatus.CANCELLED));
...
----

Each service also has a journal table with the ids of consumed messages,
allowing to identify and exclude duplicated messages after an un-clean connector shutdown.

The implementation of the _customer_ and _payment_ services isn't anything fundamentally now,
so they are omitted here for the sake of brevity.
You can find their complete source code here.

== When Things Go Wrong

A key part of implementing distributed interaction patterns like sagas is understanding how they behave in failure scenarios and making sure that (eventual) consistency is also achieved under such unforeseen circumstances.

Note that a negative outcome by any of the saga participants (e.g. if the _payment_ service rejects the payment due to an invalid credit card) is not a failure scenario here;
it is explicitly expected that participants cannot successfully execute their part of the overall flow,
resulting in the execution of appropriate compensating local transactions.
This also means that such generally anticipated failure of execution must not result in a rollback of the local database transaction,
as otherwise no reply message would be sent back to the orchestrator via the outbox.

With that in mind, let's discuss some actual failure scenarios:

The event handler of a Kafka message raises an exception:: the local database transaction will be rolled back and the incoming Kafka message will not be acknowledged with the broker; depending on the kind of exception, it may be retried after some time. In any case, monitoring should be in place to detect this situation, as the saga flow won't be able to continue until the message has been processed
The Debezium connector crashes after sending an outbox message to Kafka, but before committing the offset in the source database's transaction log:: After restarting the connector, it will continue to read the messages from the outbox table beginning at the log offset that was committed last, potentially resulting in some outbox events sent a second time; that's why all the participants need to be idempotent, as implemented in the example by means of journal tables which allow to detect if the same event is processed a second time
The Kafka broker isn't running or cannot be reached, e.g. due to a network split:: The Debezium connectors can resume their work once Kafka is available and accessable again; until then, saga flows naturally cannot proceed
A message gets processed, but acknowledging it with Kafka fails:: The message will be passed to the consuming service again, which would find the message's id in its journal table and thus ignore the duplicated message
Concurrent updates to the saga state table when processing multiple saga steps in parallel:: While we've discussed a sequential flow with the orchestrator triggering participating services one after another, one might also envision a saga implementation which processes multiple steps in parallel. In this case,
concurrently arriving reply messages may compete to update the saga state table. This situation would be detected via the optimistic locking implemented on that table, causing an event handler trying to commit an update based on a superseded version of the saga state to fail, rollback and retry

We could discuss some more cases, but the general semantics of the overall design are those of an eventually consistent system with at-least-once guarantees.

== Bonus: Distributed Tracing

When designing an event flow between distributed systems, operational insight is a key aspect of making sure everything runs correctly and efficiently.
Distributed tracing helps with that by collecting trace information from the individual systems that contribute to such interaction and allowing to examine the call flows e.g. in a web UI.

Debezium's outbox support addresses this concern through tight integration with the OpenTracing spec (support for OpenTelemetry is on the roadmap).
By putting a tool such Jaeger into place, it's just a matter of configuration to collect trace information from the _order_, _customer_, and _payment_ services and display the end-to-end spans.

TODO: add step markers from earlier chart

[.centered-image.responsive-image]
====
++++
<img src="/assets/images/saga/open-tracing.png" style="max-width:90%;" class="responsive-image" alt="Saga flow in the Jaeger UI">
++++
*Figure 6. Saga flow in the Jaeger UI*
====

The visualization flow in Jaeger nicely shows how the saga flow is triggered by the incoming REST request in the _order_ service,
an outbox message is sent to _customer_ and back to _order_,
followed by another one sent to _payment_ and back to _order_.
The tracing functionality makes it rather easy to identify unfinished flows
-- e.g. because an event handler in one of the participating services fails to process a message --
as well as performance bottlenecks,
e.g. one event handler taking particularly long for fulfilling its part of the saga flow.

== Wrap-Up

Distributed transaction protocols like XA used to be a popular choice for applying changes to a set of databases.
Within microservices architectures, this typically isn't an option, though.
Services may use non-XA compatible data stores internally,
also Apache Kafka -- as a popular infrastructure for message exchange between microservices -- doesn't support integration with XA transaction managers.

The saga pattern presents itself as a very interesting alternative,
allowing for the implementation of long-running "business transactions" which require multiple, separate services to agree on either applying or aborting a set of data changes.

Of course we should aspire for a service cut which doesn't require interaction with remote services in the first place.
For instance, it might be an option to move the credit limit logic from the example to the _order_ service itself, avoiding the coordination with the _customer_ service.
But depending on business requirements, the need for such interaction spanning multiple services may be impossible to avoid,
in particular when it comes to integrating legacy systems, or systems which are not under our control.

Compared to synchronous communication e.g. via HTTP, implementing the Saga flow using messaging infrastructure like Apache Kafka allows the participants to be nicely decoupled.
If for instance the _payment_ service isn't up and running when the _order_ service receives a new purchase order,
this doesn't matter at all.
The same goes for Kafka or Debezium, the only resource required synchronously by the _order_ service is its own database.
Once components come back up again, they will pick up from the last committed offset and continue the data flow.
We could try and wrap a resiliency layer around an architecture based on synchronous communication,
e.g. employing patterns like retries and circuit breakers.
But things would become very complex quickly: For how long to retry?
Where to buffer requests safely if an invoked service isn't available?
An asynchronous architecture based on messaging infrastructure like Apache Kafka provides the required decoupling between systems out of the box and should be the preferred approach.
Instead of doing dual writes to a service's database _and_ Kafka,
the outbox pattern implemented via CDC and Debezium provides a safe way for keeping these resources in sync.

When implementing complex patterns like sagas,
it's vital to exactly understand their constraints and semantics.
Two things to be aware of in the context of the proposed solution are the inherent eventual consistency and the limited isolation level of the overarching business transaction.
For instance the allocation of parts of the customer's credit limit may cause another, concurrently submitted order by that customer, to be rejected, also if this first order eventually also would be rejected, e.g. due to a failure with its payment.

The example project discussed in this post provides a PoC-level implementation for saga orchestration based on CDC and the outbox pattern.
It's organized into two parts:

* A generic "framework" component with the saga orchestration logic in form of a simple state machine as well as the saga execution log
* The specific implementation of the discussed order placement use case (the `OrderPlacementSaga` class shown in parts above, accompanying REST endpoints etc.)

Going forward, we might extract the former part into a reusable component,
e.g. provided through the existing Debezium Quarkus extension.
If there is interest in this, please let us know by commenting below or by reaching out on the mailing list.
While the current implementation works reliably, some features should be added;
for instance it may be desirable to optionally execute multiple saga steps concurrently.
Whether that's reasonable or not, is a business decision (e.g. in the example discussed in this post it arguably makes sense to only trigger the credit card payment once the customer credit limit check has successfully completed),
but supporting it would be trivial from a technical perspective.
Contention while updating the saga state may become a critical issue in this case;
the post https://particular.net/blog/optimizations-to-scatter-gather-sagas["Optimizations to scatter-gather sagas"] discusses potential solutions for this.
Another capability to add would be a facility for monitoring and identifying sagas who haven't been completed after some time.

The proposed implementation provides means of reliably executing business transactions with "all or nothing" semantics across a span of multiple services.
For more advanced use cases, e.g. including conditional flows, you might take a look at existing workflow engines and business process automation tools,
such as https://kogito.kie.org/[Kogito].
Another interesting technology to keep an eye on is the MicroProfile specification for long-running activities (LRA), which currently is under development.
The MicroProfile community also is discussing https://github.com/eclipse/microprofile-lra/issues/338[the integration with transactional outbox implementations] like Debezium's.

== TODO

- systems must offer compensation facility
